storage_proto: gs
storage_root: vcm-ml-experiments/2020-05-07-clouds-off-training-data
experiment:
  name: $JOBNAME
  unique_id: false
  steps_to_run:
    - one_step_run
    - create_training_data
    - baseline_run

  steps_config:
  
    one_step_run:
      command: python workflows/one_step_jobs/orchestrate_submit_jobs.py
      args:
        restart_data:
          location: $C48_RESTARTS
        experiment_yaml: $CONFIG/one_step_jobs.yml
        docker_image: $PROGNOSTIC_RUN_IMAGE
        timesteps: $ONE_STEP_TIMES
        # TODO the config-version should be included in the one_step_jobs. Similar to how k8s yamls are.
        --config-version: v0.3

    create_training_data:
      command: python -m fv3net.pipelines.create_training_data
      args:
        one_step_data:
          from: one_step_run
        diagnostics_data:
          location: $C48_DIAGNOSTICS
        timestep_splits: $TRAIN_AND_TEST_TIMES
        --runner: DataflowRunner

    baseline_run:
      command: python workflows/prognostic_c48_run/orchestrate_submit_job.py
      args:
        restart_file_dir:
          from: one_step_run
        ic_timestep: $IC_TIMESTEP 
        docker_image: $PROGNOSTIC_RUN_IMAGE
        --prog_config_yml: $CONFIG/prognostic_run.yml