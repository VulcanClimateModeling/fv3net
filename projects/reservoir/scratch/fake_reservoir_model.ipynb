{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fv3fit.reservoir import (\n",
    "    ReservoirHyperparameters,\n",
    "    Reservoir, \n",
    "    RankDivider,\n",
    ")\n",
    "\n",
    "from fv3fit.reservoir.transformers import DoNothingAutoencoder\n",
    "from fv3fit.reservoir.domain2 import OverlapRankXYDivider\n",
    "\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "import fv3fit.reservoir.readout as readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = DoNothingAutoencoder([79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperparameters = ReservoirHyperparameters(\n",
    "    state_size=3000,\n",
    "    adjacency_matrix_sparsity=0.9,\n",
    "    spectral_radius=0.5,\n",
    "    input_coupling_sparsity=0.5,\n",
    "    input_coupling_scaling=0.1,\n",
    ")\n",
    "\n",
    "rank_divider = RankDivider([8, 8], [\"x\", \"y\"], [52, 52, 79], overlap=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7900"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_divider.subdomain_size_with_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_subdomain = rank_divider.subdomain_size_with_overlap * rank_divider.n_subdomains\n",
    "output_size_subdomain = rank_divider.subdomain_xy_size_without_overlap ** 2 * 79 * rank_divider.n_subdomains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685.65673828125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size_subdomain * output_size_subdomain * 8 / 1024**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "685 GB for single C48 model tile.... with full readout matrix resolution. Need to stack matrices in sparse matrix to get a true readout layer.  But! We have a combine_readouts that loads the block diagonal matrix into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 79)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_divider.get_subdomain_extent(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An aside working through shapes of everything\n",
    "\n",
    "readout takes flat vector of subdomains stacked column by column\n",
    "\n",
    "input @ coefficenits\n",
    "\n",
    "7900 <> flattened state x 1 ?? @ \n",
    "\n",
    "7900 x ns\n",
    "hidden_state x ns\n",
    "\n",
    "(7900 + hidden_state) x ns\n",
    "nf\n",
    "\n",
    "nf*ns 1D array\n",
    "\n",
    "What are the readout weights?\n",
    "\n",
    "Ax = y\n",
    "\n",
    "nf*ns x nf*ns\n",
    "\n",
    "training inputs X is ntimes x nf*ns\n",
    "\n",
    "\n",
    "Ridge regression\n",
    "\n",
    "We have a matrix of input X and a matrix of output Y.  We want to use regression to find a matrix W such that Y = XW.  This is a linear regression problem.  Ridge regression is a regularized version of linear regression.  The regularization term is a penalty on the size of the coefficients.  The ridge coefficients minimize a penalized residual sum of squares,\n",
    "\n",
    "If X is nsamples by nfeatures, then W is nfeatures by noutputs\n",
    "\n",
    "W = (X^T X + alpha*I)^-1 X^T Y\n",
    "\n",
    "X^T X is nfeatures x nfeatures\n",
    "\n",
    "W is nfeatures x noutputs\n",
    "\n",
    "XW is nsamples x noutputs\n",
    "\n",
    "Readouts are\n",
    "\n",
    "XW + b = y\n",
    "\n",
    "for each subdomain\n",
    "\n",
    "if I stack subdomains\n",
    "\n",
    "* W (subdomain, nfeatures, noutputs)\n",
    "* X (subdomain, (sample?), nfeatures)\n",
    "* y = (subdomain, (sample?), noutputs)\n",
    "\n",
    "Subdomains leak out into the training quite a bit.  Can I contain it?\n",
    "\n",
    "`OverlapRankDivider` is some work to remove most of special care for subdomains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "divider = OverlapRankXYDivider((4, 4), (52, 52), overlap=2, z_feature=autoencoder.n_latent_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20224"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divider.flat_subdomain_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir = Reservoir(hyperparameters, input_size=divider.flat_subdomain_shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir.reset_state((divider.n_subdomains, divider.flat_subdomain_shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservoir.state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20224, 3000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservoir.W_in.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20224)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = np.random.rand(divider.n_subdomains, divider.flat_subdomain_shape[0])\n",
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservoir.reset_state(test_input.shape)\n",
    "reservoir.state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir.synchronize(np.array([test_input]*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_W_in = reservoir.W_in.tocoo()\n",
    "csc_W_in = reservoir.W_in.tocsc()\n",
    "csr_W_in = reservoir.W_in.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 20224)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coo_W_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 s ± 749 µs per loop (mean ± std. dev. of 3 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 5\n",
    "test_input @ coo_W_in.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 ms ± 340 µs per loop (mean ± std. dev. of 3 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 5\n",
    "test_input @ csc_W_in.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 ms ± 2.15 ms per loop (mean ± std. dev. of 3 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 5\n",
    "test_input @ csr_W_in.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.4453125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csc_W_in.data.nbytes / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = csr_W_in.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.2 ms ± 2.56 ms per loop (mean ± std. dev. of 3 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 3 -n 5\n",
    "test_input @ default.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462.890625"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default.nbytes / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 20224)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir.W_res = reservoir.W_res.tocsc()\n",
    "reservoir.W_in = reservoir.W_in.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "reservoir.synchronize(np.array([test_input]*25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `csc` we reduce the increment time of generating the state timeseries by 75%.  Best would be just to use a regular matrix (90% reduction), since I think 200 MB vs. 500 MB is not a big deal?\n",
    "\n",
    "## Regressor Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_hypers = readout.BatchLinearRegressorHyperparameters(l2=0.001, add_bias_term=True)\n",
    "regressor = readout.BatchLinearRegressor(reg_hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(12).reshape(6, 2)\n",
    "y = np.concatenate([\n",
    "    2 * X[:, 0:1] + 3 * X[:, 1:2],\n",
    "    4 * X[:, 0:1] + 1 * X[:, 1:2],\n",
    "    5 * X[:, 0:1] + 6 * X[:, 1:2],\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "(6, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 6, 2):\n",
    "    regressor.batch_update(X[i : i + 2], y[i : i + 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs, intercept = regressor.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = X @ coefs + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add subdomain leading dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_sub = np.array([coefs]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = np.array([X]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_sub = X_sub @ coefs_sub + intercept\n",
    "np.testing.assert_allclose(res_sub[0], res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product along trailing axis and 2nd-to-last trailing axes works with leading subdomain.  Stacking the coefficients and intercepts should be OK.  Need to fit separately? Or just form A, B separately?\n",
    "\n",
    "Note the following section was done adjusting git weights to allow a leading subdomain dimension for W.  It didn't end up making a difference so I removed.  Showing the timing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = np.array([y]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 2) (4, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_sub.shape, y_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_A = np.array([regressor.A]*4)\n",
    "joined_B = np.array([regressor.B]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_regressor = readout.BatchLinearRegressor(reg_hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_regressor.A = joined_A\n",
    "new_regressor.B = joined_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could combine the weight calculations, but it might break the least_squares solve.  Since there's fewer subdomains, it might not be that large of a difference timing-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_XtX = np.random.rand(5_000, 5_000)\n",
    "test_Xty = np.random.rand(5_000, 500)\n",
    "\n",
    "regressors = []\n",
    "for i in range(16):\n",
    "    reg = readout.BatchLinearRegressor(reg_hypers)\n",
    "    reg.A = test_XtX\n",
    "    reg.B = test_Xty\n",
    "    regressors.append(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%timeit -r 1 -n 1\n",
    "\n",
    "subdomain_readout_coeffs = []\n",
    "subdomain_intercepts = []\n",
    "for r, regressor in enumerate(regressors):\n",
    "    coefs_, intercepts_ = regressor.get_weights()\n",
    "    subdomain_readout_coeffs.append(coefs_)\n",
    "    subdomain_intercepts.append(intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "new_regressor = readout.BatchLinearRegressor(reg_hypers)\n",
    "new_regressor.A = np.array([test_XtX]*16)\n",
    "new_regressor.B = np.array([test_Xty]*16)\n",
    "new_regressor.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not any faster, so leave it as is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv3net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
