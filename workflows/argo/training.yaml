# vim: set sts=2 ts=2 tw=2 sw=2 :
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: training
spec:
  entrypoint: training
  volumes:
    - name: workdir
      emptyVol: {}
    - name: gcp-key-secret
      secret:
        defaultMode: 420
        secretName: gcp-key
  templates:
    - name: training
      inputs: &training-inputs
        parameters:
          - name: training_config
          - name: training_data_config
          - {name: validation_data_config, value: " "}
          - name: output
          - {name: cpu, value: 1000m}
          - {name: memory, value: 6Gi}
          - {name: flags, value: " "}
          - {name: no-wandb, value: "false"}
          - {name: wandb-project, value: "argo-default"}
          - {name: wandb-tags, value: ""}
          - {name: wandb-group, value: ""}
          - {name: reservoir, value: "false"}
      metadata:
        labels:
          app: ml-training
      container: &training-container
        image: us.gcr.io/vcm-ml/fv3fit
        command: &training-container-cmd ["bash", "-c", "-x"]
        env: &training-container-env
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: /secret/gcp-credentials/key.json
          - name: CLOUDSDK_AUTH_CREDENTIAL_FILE_OVERRIDE
            value: /secret/gcp-credentials/key.json
          - name: WANDB_ENTITY
            value: ai2cm
          - name: WANDB_PROJECT
            value: "{{inputs.parameters.wandb-project}}"
          - name: WANDB_RUN_GROUP
            value: "{{inputs.parameters.wandb-group}}"
          - name: WANDB_JOB_TYPE
            value: training
        envFrom: &training-container-envfrom
          - secretRef:
              name: wandb-service-token
        volumeMounts: &training-container-volmounts
          - mountPath: /secret/gcp-credentials
            name: gcp-key-secret
        args: &training-container-args
          - |

            if [ ! -z {{inputs.parameters.wandb-tags}} ]; then
              TAGS={{inputs.parameters.wandb-tags}}
              # strip possible trailing comma
              export WANDB_TAGS=$( echo $TAGS | sed 's/,$//' )
            fi

            cat <<EOF >training_config.yaml
            {{inputs.parameters.training_config}}
            EOF

            cat <<EOF >training_data.yaml
            {{inputs.parameters.training_data_config}}
            EOF

            cat <<EOF >validation_data.yaml
            {{inputs.parameters.validation_data_config}}
            EOF

            echo "Training Configuration:"
            cat training_config.yaml
            echo "Training Data Configuration:"
            cat training_data.yaml
            echo "Validation Data Configuration:"
            cat validation_data.yaml

            if grep -q '[^[:space:]]' "validation_data.yaml";
            then
                validation_arg="--validation-data-config validation_data.yaml"
            else
                validation_arg=" "
            fi

            if [ "{{inputs.parameters.no-wandb}}" == "false" ] || [[ "{{inputs.parameters.flags}}" == *"--no-wandb"* ]];
            then
              wandb_flag=""
            else
              wandb_flag="--no-wandb"
            fi

            if [ "{{inputs.parameters.reservoir}}" == "false" ];
            then
              training_routine="fv3fit.train"
            else
              training_routine="fv3fit.reservoir.train_multiple_dataset_sequence"
            fi

            python3 -m torch.utils.collect_env
            python3 -m $training_routine \
              training_config.yaml \
              training_data.yaml \
              {{inputs.parameters.output}} \
              $validation_arg \
              {{inputs.parameters.flags}} \
              $wandb_flag
      tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "med-sim-pool"
        effect: "NoSchedule"
      podSpecPatch: |
        containers:
          - name: main
            resources:
              limits:
                cpu: "{{inputs.parameters.cpu}}"
                memory: "{{inputs.parameters.memory}}"
              requests:
                cpu: "{{inputs.parameters.cpu}}"
                memory: "{{inputs.parameters.memory}}"
    - name: training-gpu-def
      inputs: *training-inputs
      container: *training-container
      metadata:
        labels:
          app: ml-training
      tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "gpu-sim-pool"
        effect: "NoSchedule"
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      podSpecPatch: |
        containers:
          - name: main
            resources:
              limits:
                cpu: "{{inputs.parameters.cpu}}"
                memory: "{{inputs.parameters.memory}}"
                nvidia.com/gpu: 1
              requests:
                cpu: "{{inputs.parameters.cpu}}"
                memory: "{{inputs.parameters.memory}}"
    - name: training-torch-def
      inputs: *training-inputs
      container:
        image: us.gcr.io/vcm-ml/fv3fit_torch
        command: *training-container-cmd
        env: *training-container-env
        envFrom: *training-container-envfrom
        volumeMounts: *training-container-volmounts
        args: *training-container-args
      metadata:
        labels:
          app: ml-training
      tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "gpu-sim-pool"
        effect: "NoSchedule"
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      podSpecPatch: |
        containers:
          - name: main
            resources:
              limits:
                cpu: "{{inputs.parameters.cpu}}"
                memory: "{{inputs.parameters.memory}}"
                nvidia.com/gpu: 1
              requests:
                cpu: "{{inputs.parameters.cpu}}"
                memory: "{{inputs.parameters.memory}}"
