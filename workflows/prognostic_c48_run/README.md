Prognostic model run workflow
=============================

This workflow makes a coupled C48 FV3 run with a scikit-learn model. This workflow
1. includes runfile `sklearn_runfile.py` which can be used with `fv3run`
1. uses the `prognostic_run` docker image, built by `fv3net/docker/prognostic_run/Dockerfile`
1. is typically run on the cloud via the `prognostic-run` Argo WorkflowTemplate at 
`fv3net/workflows/argo/prognostic-run.yaml`

(Authenticating) with google cloud
--------------------------------

This workflow needs to access google cloud storage within docker. To do this,
it expects that the environmental variable GOOGLE_APPLICATION_CREDENTIALS
will point to a valid service account key on the host system. For example,

    export GOOGLE_APPLICATION_CREDENTIALS=<path/to/key.json>

Quickstart
----------

The tests can be run with

	make test

Development
-----------

This workflow uses docker-compose to bootstrap a development environment. This
environment is based off the `prognostic_run` docker image, but has bind-mounts
to the packages in "/external" of this repository and this directory, which
allows locally developing this workflow and its dependencies. To enter a
development bash shell, run

    make dev

This command may take some time to run, as it needs to re-compile the Fortran and
Cython sources you have on your local machine.

If you change the base image (not the files which get bind-mounted), you will need
to re-build the docker-compose image using

    make build


Prognostic Run Configuration
----------------------------

A complete fv3config object for the prognostic run is generated by the `prepare_config.py`
script. Call `python prepare_config.py -h` to see arguments. This script will update the specified base fv3config with any values specified in `user_config` argument and apply other configuration options. 

The runfile can be configured to run in the following configurations:
1. Machine learning
1. Nudging
1. Baseline (no ML or nudging)

Machine learning is done by including a machine learning model path in the `scikit-learn` config section or via a `--model_url` command line argument. Nudging is done by including a `nudging` config section. A baseline run is done by providing neither an ML model nor a nudging section.

### Configuring a machine learning run

The ML model and location for zarr output can be configured using `fv3config.yml`. Add/modify the `scikit_learn` entry of the yaml file as follows (here to use a model from fv3fit.sklearn):
```
scikit_learn:
  model: gs://vcm-ml-data/test-annak/ml-pipeline-output
  model_type: scikit_learn
```
Or to use a model from fv3fit.keras:
```
scikit_learn:
  model: gs://vcm-ml-scratch/brianh/train-keras-model-testing/fv3fit-unified
  model_type: keras
```

Alternatively, the model path can also be specified via the command line argument `--model_url`.

If some variables names used for input variables in the scikit-learn model are inconsistent with the variable names used by the python wrapper, this can be handled by the optional `input_variable_standard_names` entry in the `scikit_learn` entry of the config yaml:
```
scikit_learn:
  input_variable_standard_names:
    DSWRFtoa_train: total_sky_downward_shortwave_flux_at_top_of_atmosphere
```

### Configuring a nudging run

Nudging requires a `nudging` section within the fv3config object, which contains a mapping (`timescale-hours`) of variable names to nudging timescales. See nudging/README.

### Configuring diagnostics

To modify the diagnostic output frequency of the run (which defaults to every 15 minutes), provide to `prepare_config.py` either the command line argument `--output-timestamps` as a file path or `--output_frequency` as minutes, but not both.

Default diagnostics are computed and saved to .zarrs depending on whether an ML, nudging, or baseline run is chosen. To save additional tendencies and storages across physics and nudging/ML time steps, add `step_tendency_variables` and `step_storage_variables` entries to specify these variables. (If not specified these default to `air_temperature` and `specific_humidity` for `tendency`, and `specific_humidity` and `total_water` for `storage`.) Then add an additional output .zarr which includes among its variables the desired tendencies and/or path storages of these variables due to physics (`_due_to_fv3_physics`) and/or ML/nudging (`_due_to_python`). See the example below of an additional diagnostic file configuration. 

### Additional diagnostic example `config.yml` 

```yaml
namelist:
  coupler_nml:
    hours: 0
    minutes: 60
    seconds: 0
step_tendency_variables: 
  - air_temperature
  - specific_humidity
  - cloud_water_mixing_ratio
step_storage_variables: 
  - specific_humidity
  - cloud_water_mixing_ratio
diagnostics:
  - name: step_diags.zarr
    variables:
      - tendency_of_air_temperature_due_to_fv3_physics
      - tendency_of_specific_humidity_due_to_fv3_physics
      - tendency_of_cloud_water_mixing_ratio_due_to_fv3_physics
      - storage_of_specific_humidity_path_due_to_fv3_physics
      - storage_of_cloud_water_mixing_ratio_path_due_to_fv3_physics
      - tendency_of_air_temperature_due_to_python
      - tendency_of_specific_humidity_due_to_python
      - storage_of_specific_humidity_path_due_to_python
```
