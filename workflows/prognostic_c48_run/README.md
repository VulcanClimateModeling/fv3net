Prognostic model run workflow
=============================

[Sphinx Documentation](https://vulcanclimatemodeling.com/docs/prognostic_c48_run/)

This workflow makes a coupled C48 FV3 run with a scikit-learn model. This workflow
1. includes runfile `sklearn_runfile.py` which can be used with `fv3run`
1. uses the `prognostic_run` docker image, built by `fv3net/docker/prognostic_run/Dockerfile`
1. is typically run on the cloud via the `prognostic-run` Argo WorkflowTemplate at 
`fv3net/workflows/argo/prognostic-run.yaml`

(Authenticating) with google cloud
--------------------------------

This workflow needs to access google cloud storage within docker. To do this,
it expects that the environmental variable GOOGLE_APPLICATION_CREDENTIALS
will point to a valid service account key on the host system. For example,

    export GOOGLE_APPLICATION_CREDENTIALS=<path/to/key.json>

Quickstart
----------

The tests can be run with

	make test

Development
-----------

This workflow uses docker-compose to bootstrap a development environment. This
environment is based off the `prognostic_run` docker image, but has bind-mounts
to the packages in "/external" of this repository and this directory, which
allows locally developing this workflow and its dependencies. To enter a
development bash shell, run

    make dev

This command may take some time to run, as it needs to re-compile the Fortran and
Cython sources you have on your local machine.

If you change the base image (not the files which get bind-mounted), you will need
to re-build the docker-compose image using

    make build


Prognostic Run Configuration
----------------------------

A complete fv3config object for the prognostic run is generated by the `prepare_config.py`
script. Call `python prepare_config.py -h` to see arguments. This script will update the specified base fv3config with any values specified in `user_config` argument and apply other configuration options. 

The runfile can be configured to run in the following configurations:
1. Machine learning (prognostic)
1. Nudge-to-fine
1. Baseline (no ML or nudging)
1. Nudge-to-obs

Machine learning is done by including a machine learning model path in the `scikit-learn` config section or via a `--model_url` command line argument. Nudge-to-fine is done by including a `nudging` config section. A baseline run is done by providing neither an ML model nor nudging arguments. A nudge-to-obs run can be executed by including the argument `--nudge-to-observations URL` to `prepare_config.py`; note that nudge-to-obs is not mutually exclusive with any of the first three options as it is conducted within the Fortran physics routine. 

### Configuring a machine learning run

Alternatively, the model path can also be specified via the command line argument `--model_url`.

If some variables names used for input variables in the scikit-learn model are inconsistent with the variable names used by the python wrapper, this can be handled by the optional `input_variable_standard_names` entry in the `scikit_learn` entry of the config yaml:
```
scikit_learn:
  input_variable_standard_names:
    DSWRFtoa_train: total_sky_downward_shortwave_flux_at_top_of_atmosphere
```

### Configuring diagnostics with prepare_config.py

To modify the output frequency of the run's Python diagnostics (which defaults to every 15 minutes), provide to `prepare_config.py` either the command line argument `--output-timestamps` as a file path or `--output_frequency` as minutes, but not both. Fortran diagnostics are configured through the diag_table.

Default diagnostics are computed and saved to .zarrs depending on whether ML, nudge-to-fine, nudge-to-obs, or baseline runs are chosen. To save additional tendencies and storages across physics and nudging/ML time steps, add `step_tendency_variables` and `step_storage_variables` entries to specify these variables. (If not specified these default to `air_temperature`, `specific_humidity`, `eastward_wind`, and `northward_wind` for `tendency`, and `specific_humidity` and `total_water` for `storage`.) Then add an additional output .zarr which includes among its variables the desired tendencies and/or path storages of these variables due to physics (`_due_to_fv3_physics`) and/or ML/nudging (`_due_to_python`). See the example below of an additional diagnostic file configuration. 

### Additional diagnostic example `config.yml` 

```yaml
namelist:
  coupler_nml:
    hours: 0
    minutes: 60
    seconds: 0
step_tendency_variables: 
  - air_temperature
  - specific_humidity
  - eastward_wind
  - northward_wind
  - cloud_water_mixing_ratio
step_storage_variables: 
  - specific_humidity
  - cloud_water_mixing_ratio
diagnostics:
  - name: step_diags.zarr
    chunks:
      time: 4
    variables:
      - tendency_of_cloud_water_mixing_ratio_due_to_fv3_physics
      - storage_of_specific_humidity_path_due_to_fv3_physics
      - storage_of_cloud_water_mixing_ratio_path_due_to_fv3_physics
      - storage_of_specific_humidity_path_due_to_python
```
